{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2132a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--target_model TARGET_MODEL]\n",
      "                             [--target_model_path TARGET_MODEL_PATH]\n",
      "                             [--evaluator_model EVALUATOR_MODEL]\n",
      "                             [--evaluator_model_path EVALUATOR_MODEL_PATH]\n",
      "                             [--generator_model_path GENERATOR_MODEL_PATH]\n",
      "                             [--device DEVICE] --experiment_name\n",
      "                             EXPERIMENT_NAME --config_file CONFIG_FILE\n",
      "                             [--private_imgs_path PRIVATE_IMGS_PATH]\n",
      "                             [--n_classes N_CLASSES]\n",
      "                             [--n_classes_evaluator N_CLASSES_EVALUATOR]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --experiment_name, --config_file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kungao/anaconda3/envs/Dy/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3450: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from classify import *\n",
    "from generator import *\n",
    "from discri import *\n",
    "from torch.nn import  DataParallel\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os, logging\n",
    "import numpy as np\n",
    "from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser\n",
    "import yaml\n",
    "from brep_mi import attack\n",
    "\n",
    "\n",
    "class DPSGD(torch.optim.Optimizer):\n",
    "    \"\"\"\n",
    "    Distributed Private Stochastic Gradient Descent optimizer for PyTorch models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, params, lr, batch_size, epsilon, delta):\n",
    "        \"\"\"\n",
    "        Initialize the optimizer.\n",
    "        \n",
    "        Parameters:\n",
    "            - params (iterable): Iterable of model parameters to be trained\n",
    "            - lr (float): Learning rate\n",
    "            - batch_size (int): Batch size\n",
    "            - epsilon (float): Privacy budget parameter\n",
    "            - delta (float): Privacy budget parameter\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon = epsilon\n",
    "        self.delta = delta\n",
    "        \n",
    "        # Compute the clipping bound\n",
    "        #self.clipping_bound = torch.sqrt(2 * torch.log(1.25 / delta)) * epsilon / batch_size\n",
    "        self.clipping_bound = (torch.sqrt(2 * torch.log(torch.tensor(1.25 / delta))) * epsilon / batch_size).cuda()\n",
    "\n",
    "        # Call the superclass constructor\n",
    "        super(DPSGD, self).__init__(params, defaults={})\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"\n",
    "        Perform a single optimization step.\n",
    "        \n",
    "        Parameters:\n",
    "            - closure (callable): A closure that reevaluates the model and returns the loss.\n",
    "        \n",
    "        Returns:\n",
    "            - None\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "        \n",
    "        # Loop over the parameters\n",
    "        for group in self.param_groups:\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                # Compute the clipped gradients\n",
    "                clipped_grad = param.grad.data.clamp_(-self.clipping_bound, self.clipping_bound)\n",
    "                \n",
    "                clipped_grad = clipped_grad.cuda() # put on GPU\n",
    "                \n",
    "                # Add Gaussian noise to the gradients\n",
    "                noise = torch.randn_like(clipped_grad) * self.clipping_bound * self.epsilon\n",
    "                noise = noise.cuda() # put on GPU\n",
    "                noisy_grad = clipped_grad + noise\n",
    "                \n",
    "                # Update the parameters\n",
    "                param.data.add_(-self.lr, noisy_grad.cuda()) # bring back to CPU\n",
    "                \n",
    "        return loss\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    global args, logger\n",
    "\n",
    "    parser = ArgumentParser(description='A tool that applies Label Only Model Inversion Attack using labels only.')\n",
    "    parser.add_argument('--target_model', default='FaceNet64', help='VGG16 | IR152 | FaceNet64')\n",
    "    parser.add_argument('--target_model_path', type=str, help='path to target_model')\n",
    "    parser.add_argument('--evaluator_model', default='FaceNet', help='VGG16 | IR152 | FaceNet64| FaceNet')\n",
    "    parser.add_argument('--evaluator_model_path', default='models/target_ckp/FaceNet_95.88.tar', help='path to evaluator_model')\n",
    "    parser.add_argument('--generator_model_path', type=str, help='path to generator model')\n",
    "    parser.add_argument('--device', type=str, default='0', help='Device to use. Like cuda, cuda:0 or cpu')\n",
    "    parser.add_argument('--experiment_name', type=str, default='default_test1', help='experiment name for experiment directory', required = True)\n",
    "    \n",
    "    parser.add_argument('--config_file', type=str, help='config file that has attack params', required = True)\n",
    "    parser.add_argument('--private_imgs_path', type=str, default='', help='Path to groundtruth images to copy them to attack dir. Empty string means, our tool will not copy.')\n",
    "    parser.add_argument('--n_classes', type=int, default=1000, help='num of classes of target model')\n",
    "    parser.add_argument('--n_classes_evaluator', type=int, default=1000, help='num of classes of evaluator model')\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    print(args)\n",
    "    print(\"=> loading models ...\")    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.device\n",
    "    \n",
    "    \n",
    "    # loading attack params\n",
    "    with open (args.config_file) as config_file:\n",
    "        attack_params = yaml.load(config_file)        \n",
    "    print (attack_params)\n",
    "    \n",
    "    \n",
    "    #loading the models\n",
    "    n_classes = args.n_classes\n",
    "\n",
    "    if args.target_model.startswith(\"VGG16\"):\n",
    "        target_model = VGG16(n_classes)\n",
    "    elif args.target_model.startswith('IR152'):\n",
    "        target_model = IR152(n_classes)\n",
    "    elif args.target_model == \"FaceNet64\":\n",
    "        target_model = FaceNet64(n_classes)\n",
    "        \n",
    "    path_target_model = args.target_model_path\n",
    "    target_model = torch.nn.DataParallel(target_model).cuda()\n",
    "    model_params = list(targetmodel.parameters())\n",
    "    lr = 0.01\n",
    "    batch_size = 32\n",
    "    epsilon = 1.0\n",
    "    delta = 1e-5\n",
    "    optimizer = DPSGD(model_params, lr, batch_size, epsilon, delta)\n",
    "    \n",
    "    ckp_target_model = torch.load(path_target_model)\n",
    "    target_model.load_state_dict(ckp_target_model['state_dict'], strict=False)\n",
    "    \n",
    "   \n",
    "    path_G = args.generator_model_path\n",
    "    G = Generator(attack_params['z_dim'])\n",
    "    G = torch.nn.DataParallel(G).cuda()\n",
    "    ckp_G = torch.load(path_G)\n",
    "    G.load_state_dict(ckp_G['state_dict'], strict=False)\n",
    "\n",
    "    if args.evaluator_model == 'FaceNet':\n",
    "        E = FaceNet(args.n_classes_evaluator)\n",
    "    elif args.evaluator_model == 'FaceNet64':\n",
    "        E = FaceNet64(args.n_classes_evaluator)\n",
    "        \n",
    "    E = torch.nn.DataParallel(E).cuda()\n",
    "    path_E = args.evaluator_model_path\n",
    "    ckp_E = torch.load(path_E)\n",
    "    E.load_state_dict(ckp_E['state_dict'], strict=False)\n",
    "    \n",
    "    \n",
    "    target_model.eval()\n",
    "    G.eval()\n",
    "    E.eval()\n",
    "    \n",
    "    \n",
    "    # prepare working dirs\n",
    "    attack_imgs_dir = 'decision/attack_imgs/'+args.experiment_name\n",
    "    os.makedirs(attack_imgs_dir, exist_ok = True)\n",
    "    \n",
    "    \n",
    "    # do the attack\n",
    "    attack( attack_params,\n",
    "            target_model,\n",
    "            E,\n",
    "            G,\n",
    "            attack_imgs_dir,\n",
    "            args.private_imgs_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34984ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
